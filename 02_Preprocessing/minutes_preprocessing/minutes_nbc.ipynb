{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "def present_rate():\n",
    "    b = []\n",
    "    dataframe_list = []\n",
    "    base_rate = pd.read_csv('/Users/stillssi/Desktop/BOK_TEAM_4/01_Crawling/base_rate/base_rate.csv')\n",
    "    base_rate['date'] = pd.to_datetime(base_rate['date'])\n",
    "    base_rate = base_rate.sort_values(by='date',ascending=True)\n",
    "    base_rate.set_index('date', inplace=True)\n",
    "    for i in range(len(base_rate.index)):\n",
    "        start_date = pd.to_datetime(base_rate.index[i]) ## 시작 날짜\n",
    "        try:\n",
    "            tmp = {}\n",
    "            end_date = pd.to_datetime(base_rate.index[i+1]) ## 마지막 날짜\\\n",
    "            bet = pd.date_range(start_date,end_date+ timedelta(days = -1),freq='D').values\n",
    "            \n",
    "            tmp = {'date': bet, 'rate': [base_rate.loc[start_date].rate]*len(bet)} \n",
    "            b = pd.DataFrame(tmp)\n",
    "            b.set_index('date', inplace=True)\n",
    "            dataframe_list.append(b)\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "    merge_dataframe = pd.concat(dataframe_list)\n",
    "    merge_dataframe = merge_dataframe.iloc[46:4100]\n",
    "    merge_dataframe.to_csv('./base_rate.csv')\n",
    "    return merge_dataframe\n",
    "\n",
    "present_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "def future_rate(fra):\n",
    "    da_list, ra_list = [],[]\n",
    "    base_r = fra\n",
    "    for i in range(len(base_r.index)):\n",
    "        if base_r.index[i] == datetime.strptime('2022-01-01', '%Y-%m-%d'):\n",
    "            break\n",
    "        da_list.append(base_r.index[i])\n",
    "        ra_list.append(base_r.loc[base_r.index[i] + timedelta(days = 28)].rate)\n",
    "        \n",
    "    label_ = {'date': da_list, 'rate': ra_list}\n",
    "    label_df = pd.DataFrame(label_)\n",
    "    label_df.set_index('date', inplace=True)\n",
    "    return label_df\n",
    "\n",
    "pre_rate = present_rate()\n",
    "fu_rate = future_rate(pre_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def please2(x):\n",
    "    return 1 if x > 0.03 else -1 if x < -0.03 else 0\n",
    "new_df = (pre_rate - fu_rate)\n",
    "new_df['label'] = new_df['rate'].apply(lambda x : please2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('base_rate_label.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "import os\n",
    "from eKoNLPy.ekonlpy.sentiment import MPCK\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def minutes_ngram():\n",
    "    '''\n",
    "    의사록 5-gram 함수\n",
    "    return: n-gram 개수\n",
    "    '''\n",
    "    i = 0\n",
    "    mpck = MPCK()\n",
    "    TXT_DIR = '//Users/stillssi/Desktop/minutes/Data/split_data/' #split text 파일 경로\n",
    "    label_data = pd.read_csv('/Users/stillssi/Desktop/BOK_TEAM_4/02_Preprocessing/minutes_preprocessing/base_rate_label.csv')\n",
    "    file_list = os.listdir(TXT_DIR)\n",
    "    df = pd.DataFrame(columns=['date', 'ngrams'])\n",
    "    label_data['date'] = pd.to_datetime(label_data['date'], infer_datetime_format=True)\n",
    "    for file in file_list:\n",
    "\n",
    "        ngram_list = []\n",
    "        text = []\n",
    "        try:\n",
    "            f = open(TXT_DIR+file,'r', encoding='utf-8')\n",
    "            day = datetime.strptime(file[:-4], '%Y.%m.%d')\n",
    "            \n",
    "            lines = f.readlines()\n",
    "\n",
    "            hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "            \n",
    "            for l in lines:\n",
    "                \n",
    "                result = hangul.sub('', l)\n",
    "                result = result.split(' ')\n",
    "                result_removed = [i for i in result if i != '']\n",
    "                line = ' '.join(result_removed)\n",
    "                text.append(line)\n",
    "\n",
    "            if len(text) == 1:\n",
    "                pass\n",
    "            else:\n",
    "                text = list(itertools.chain(*text))\n",
    "            resultt = ''.join(text)\n",
    "            tokens = mpck.tokenize(resultt)\n",
    "            ngrams = mpck.ngramize(tokens)\n",
    "            ngram_list.append(ngrams)\n",
    "\n",
    "            ngram_list= list(itertools.chain(*ngram_list))\n",
    "            df.loc[i]=[day,ngram_list]\n",
    "            i = i+1    \n",
    "    \n",
    "        except Exception as e:\n",
    "            pass\n",
    "    df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True)\n",
    "    \n",
    "\n",
    "    df_LEFT_JOIN = pd.merge(df, label_data, left_on='date', right_on='date', how='left')\n",
    "    minutes_labeling_data = df_LEFT_JOIN.sort_values(by='date',ascending=True)\n",
    "    minutes_labeling_data.set_index('date', inplace=True)\n",
    "    minutes_labeling_data.sort_index(ascending=True, inplace=True)\n",
    "    minutes_labeling_data.to_csv('./minutes_ngram_labeling.csv')\n",
    "    return minutes_labeling_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ngram = minutes_ngram()\n",
    "min_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import itertools\n",
    "\n",
    "ngram_list = list(itertools.chain(*list(min_ngram['ngrams'])))\n",
    "up_ngram_list = list(itertools.chain(*(list(min_ngram[min_ngram['label']==1]['ngrams']))))\n",
    "down_ngram_list = list(itertools.chain(*(list(min_ngram[min_ngram['label']==-1]['ngrams']))))\n",
    "same_ngram_list = list(itertools.chain(*(list(min_ngram[min_ngram['label']==0]['ngrams']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(ngram_list) \n",
    "count_df = pd.DataFrame(list(zip(fdist.keys(), fdist.values())))\n",
    "count_df.columns = ['ngrams', 'n_sums']\n",
    "\n",
    "up_fdist = nltk.FreqDist(up_ngram_list)\n",
    "up_count_df = pd.DataFrame(list(zip(up_fdist.keys(), up_fdist.values())))\n",
    "up_count_df.columns = ['ngrams', 'n_sums']\n",
    "\n",
    "down_fdist = nltk.FreqDist(down_ngram_list)\n",
    "down_count_df = pd.DataFrame(list(zip(down_fdist.keys(), down_fdist.values())))\n",
    "down_count_df.columns = ['ngrams', 'n_sums']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_count_df.to_csv('./adsf.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df.columns = ['ngrams', 'n_sums']\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_df = pd.merge(left = count_df, right = up_count_df, how='left', on='ngrams')\n",
    "print(ngrams_df) # x=count_df, y=up_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_df = pd.merge(left = ngrams_df, right = down_count_df, how='left', on='ngrams') # n_sums=down_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_df.columns = ['ngrams', 'n_count_df', 'n_up_count_df', 'n_down_count_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ngrams_df)):\n",
    "    up_nbc = ngrams_df.loc[i, 'n_up_count_df'] / ngrams_df['n_up_count_df'].sum()\n",
    "    down_nbc = ngrams_df.loc[i, 'n_down_count_df'] / ngrams_df['n_down_count_df'].sum()\n",
    "    ngrams_df.loc[i, 'up_NBC'] = up_nbc\n",
    "    ngrams_df.loc[i, 'down_NBC'] = down_nbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('project1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb0c2b2e33a8bbc9324abe172f16f5be0a36d26d93f9b38dc3fecfa8c79d8138"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
